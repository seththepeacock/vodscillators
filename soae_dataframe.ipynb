{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from plots import *\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def plot_mags():\n",
    "    m = get_mags(wf, sr=44100, t_win=1, num_wins=30, dict=True)\n",
    "    mags = m['mags']\n",
    "    freq_ax = m['freq_ax']\n",
    "    plt.plot(freq_ax, np.log10(mags)*20)\n",
    "    plt.title(fn)\n",
    "    plt.show()\n",
    "    \n",
    "# get the main directory in my computer\n",
    "main_path_str = \"C:\\\\Users\\\\Owner\\OneDrive\\\\Desktop\\\\SOAE Data\\\\\"\n",
    "# we'll process each subfolder separately since each is likely to have its own quirks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolder = \"Curated Data\"\n",
    "    \n",
    "# We'll build our dataframe by making a dictionary of lists and appending to them\n",
    "data = {\n",
    "    'filepath': [],\n",
    "    'wf': [],  \n",
    "    'species': [],\n",
    "    'sr': [],\n",
    "}\n",
    "\n",
    "# First navigate to our directory\n",
    "directory_path = Path(main_path_str + subfolder)\n",
    "\n",
    "# track which file we're on\n",
    "n_files = sum(1 for _ in directory_path.rglob('*') if _.is_file())\n",
    "i=0\n",
    "\n",
    "# now loop through all files in that collection\n",
    "for fp in directory_path.rglob('*'):\n",
    "    # Check if it's a file\n",
    "    if fp.is_file():  \n",
    "        i += 1\n",
    "        print(f\"Processing file {i}/{n_files}\")\n",
    "        # Cut off the beginning of the filepath since it's unnecessary for our dataframe (fps = file path shortened)\n",
    "        main_path = Path(main_path_str)\n",
    "        fps = str(fp.relative_to(main_path))\n",
    "        \n",
    "        # Get the filename itself (without its containing folders)\n",
    "        fn = fp.name\n",
    "        # now we actually open the waveform here\n",
    "        # Check if it's a .txt or .mat file\n",
    "        try:\n",
    "            if fp.suffix == '.mat':\n",
    "                mat = scipy.io.loadmat(fp)\n",
    "                if 'wf' in mat:\n",
    "                    wf = np.squeeze(mat['wf'])\n",
    "                else: \n",
    "                    print(f\"Not sure how to process {fp}\")\n",
    "            if fp.suffix == '.txt':\n",
    "                wf = np.loadtxt(fp)\n",
    "            # Let's make sure this waveform is a 1D array\n",
    "            if len(wf.shape) > 1:\n",
    "                if fn == 'cricket_177.txt':\n",
    "                    wf = wf[:, 1]\n",
    "                else:\n",
    "                    print(f\"Waveform from {fps} isn't 1D!\")\n",
    "        except:\n",
    "            f\"Uh oh! Issue when loading {fp}\"\n",
    "            \n",
    "        # if str(fps).split(\"\\\\\")[1]=='Tree Cricket':\n",
    "        #     plot_mags()\n",
    "        \n",
    "        \n",
    "        # try and get the species name\n",
    "        fn_species = fn.split(\"_\")[0]\n",
    "        \n",
    "        match fn_species:\n",
    "            case 'anole':\n",
    "                species = \"Anole\"\n",
    "            case 'cricket':\n",
    "                species = \"Cricket\"\n",
    "            case 'human':\n",
    "                species = \"Human\"\n",
    "            case 'owl':\n",
    "                species = \"Owl\"\n",
    "            case _:\n",
    "                species = \"\"\n",
    "        \n",
    "        if species != \"Owl\":\n",
    "            sr = 44100\n",
    "        else:\n",
    "            sr = 0\n",
    "            \n",
    "                \n",
    "        # add everything to our df dict\n",
    "        data['filepath'].append(fps)\n",
    "        data['wf'].append(wf)\n",
    "        data['species'].append(species)\n",
    "        data['sr'].append(sr)\n",
    "\n",
    "# turn this into a pandas dataframe\n",
    "df = pd.DataFrame(data)\n",
    "df['filepath'] = df['filepath'].astype(str)\n",
    "df['species'] = df['species'].astype(str)\n",
    "# save this as a parquet file for efficient dataframe storage (use pyarrow since the 'wf' column has different length lists)\n",
    "df.to_parquet(f'{subfolder}.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolder = \"Curated Data\"\n",
    "    \n",
    "# We'll build our dataframe by making a dictionary of lists and appending to them\n",
    "data = {\n",
    "    'filepath': [],\n",
    "    'wf': [],  \n",
    "    'species': [],\n",
    "    'sr': [],\n",
    "}\n",
    "\n",
    "# First navigate to our directory\n",
    "directory_path = Path(main_path_str + subfolder)\n",
    "\n",
    "# track which file we're on\n",
    "n_files = sum(1 for _ in directory_path.rglob('*') if _.is_file())\n",
    "i=0\n",
    "\n",
    "# now loop through all files in that collection\n",
    "for fp in directory_path.rglob('*'):\n",
    "    # Check if it's a file\n",
    "    if fp.is_file():  \n",
    "        i += 1\n",
    "        print(f\"Processing file {i}/{n_files}\")\n",
    "        # Cut off the beginning of the filepath since it's unnecessary for our dataframe (fps = file path shortened)\n",
    "        main_path = Path(main_path_str)\n",
    "        fps = str(fp.relative_to(main_path))\n",
    "        \n",
    "        # Get the filename itself (without its containing folders)\n",
    "        fn = fp.name\n",
    "        # now we actually open the waveform here\n",
    "        # Check if it's a .txt or .mat file\n",
    "        try:\n",
    "            if fp.suffix == '.mat':\n",
    "                mat = scipy.io.loadmat(fp)\n",
    "                if 'wf' in mat:\n",
    "                    wf = np.squeeze(mat['wf'])\n",
    "                else: \n",
    "                    print(f\"Not sure how to process {fp}\")\n",
    "            if fp.suffix == '.txt':\n",
    "                wf = np.loadtxt(fp)\n",
    "            # Let's make sure this waveform is a 1D array\n",
    "            if len(wf.shape) > 1:\n",
    "                if fn == 'cricket_177.txt':\n",
    "                    wf = wf[:, 1]\n",
    "                else:\n",
    "                    print(f\"Waveform from {fps} isn't 1D!\")\n",
    "        except:\n",
    "            f\"Uh oh! Issue when loading {fp}\"\n",
    "            \n",
    "        # if str(fps).split(\"\\\\\")[1]=='Tree Cricket':\n",
    "        #     plot_mags()\n",
    "        \n",
    "        \n",
    "        # try and get the species name\n",
    "        fn_species = fn.split(\"_\")[0]\n",
    "        \n",
    "        match fn_species:\n",
    "            case 'anole':\n",
    "                species = \"Anole\"\n",
    "            case 'cricket':\n",
    "                species = \"Cricket\"\n",
    "            case 'human':\n",
    "                species = \"Human\"\n",
    "            case 'owl':\n",
    "                species = \"Owl\"\n",
    "            case _:\n",
    "                species = \"\"\n",
    "        \n",
    "        if species != \"Owl\":\n",
    "            sr = 44100\n",
    "        else:\n",
    "            sr = 0\n",
    "            \n",
    "                \n",
    "        # add everything to our df dict\n",
    "        data['filepath'].append(fps)\n",
    "        data['wf'].append(wf)\n",
    "        data['species'].append(species)\n",
    "        data['sr'].append(sr)\n",
    "\n",
    "# turn this into a pandas dataframe\n",
    "df = pd.DataFrame(data)\n",
    "df['filepath'] = df['filepath'].astype(str)\n",
    "df['species'] = df['species'].astype(str)\n",
    "# save this as a parquet file for efficient dataframe storage (use pyarrow since the 'wf' column has different length lists)\n",
    "df.to_parquet('curated_data.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolder = \"Extra Owl\"\n",
    "    \n",
    "# We'll build our dataframe by making a dictionary of lists and appending to them\n",
    "data = {\n",
    "    'filepath': [],\n",
    "    'wf': [],  \n",
    "    'species': [],\n",
    "    'sr': [],\n",
    "}\n",
    "\n",
    "species = \"Owl\"\n",
    "\n",
    "# First navigate to our directory\n",
    "directory_path = Path(main_path_str + subfolder)\n",
    "\n",
    "# track which file we're on\n",
    "n_files = sum(1 for _ in directory_path.rglob('*') if _.is_file())\n",
    "i=0\n",
    "\n",
    "# now loop through all files in that collection\n",
    "for fp in directory_path.rglob('*'):\n",
    "    # Check if it's a file\n",
    "    if fp.is_file():  \n",
    "        i += 1\n",
    "        print(f\"Processing file {i}/{n_files}\")\n",
    "        # Cut off the beginning of the filepath since it's unnecessary for our dataframe (fps = file path shortened)\n",
    "        main_path = Path(main_path_str)\n",
    "        fps = str(fp.relative_to(main_path))\n",
    "        \n",
    "        # Get the filename itself (without its containing folders)\n",
    "        fn = fp.name\n",
    "        # now we actually open the waveform here\n",
    "        # Check if it's a .txt or .mat file\n",
    "        try:\n",
    "            if fp.suffix == '.mat':\n",
    "                mat = scipy.io.loadmat(fp)\n",
    "                if 'wf' in mat:\n",
    "                    wf = np.squeeze(mat['wf'])\n",
    "                else: \n",
    "                    print(f\"Not sure how to process {fp}\")\n",
    "            if fp.suffix == '.txt':\n",
    "                wf = np.loadtxt(fp)\n",
    "            # Let's make sure this waveform is a 1D array\n",
    "            if len(wf.shape) > 1:\n",
    "                print(f\"Waveform from {fps} isn't 1D!\")\n",
    "        except:\n",
    "            f\"Uh oh! Issue when loading {fp}\"\n",
    "            \n",
    "        if str(fps).split(\"\\\\\")[1]=='Oldenberg Data (2013) (44.1kHz)':\n",
    "            sr = 44100\n",
    "        elif str(fps).split(\"\\\\\")[1]=='Pim owl files (48 kHz)':\n",
    "            sr = 48000\n",
    "        else:\n",
    "            print(\"UH OH WHERE ARE WE\")\n",
    "        \n",
    "            \n",
    "                \n",
    "        # add everything to our df dict\n",
    "        data['filepath'].append(fps)\n",
    "        data['wf'].append(wf)\n",
    "        data['species'].append(species)\n",
    "        data['sr'].append(sr)\n",
    "\n",
    "# turn this into a pandas dataframe\n",
    "df = pd.DataFrame(data)\n",
    "df['filepath'] = df['filepath'].astype(str)\n",
    "df['species'] = df['species'].astype(str)\n",
    "# save this as a parquet file for efficient dataframe storage (use pyarrow since the 'wf' column has different length lists)\n",
    "df.to_parquet(f'{subfolder}.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
